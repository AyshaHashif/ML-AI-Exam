{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEn7ln9eh2HhI9t/WZ0OOl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","\n","# Load dataset\n","df = pd.read_csv(\"drugLibTrain_raw.tsv\", sep=\"\\t\")\n","# Use a small subset for fast training\n","df = df.sample(n=50, random_state=42)\n","# Use 'benefitsReview' and 'sideEffectsReview' as reviews and 'rating' for sentiment\n","df = df.dropna(subset=[\"benefitsReview\", \"sideEffectsReview\", \"rating\"])\n","\n","# Combine the review columns into a single 'review' column\n","df['review'] = df['benefitsReview'].fillna('') + ' ' + df['sideEffectsReview'].fillna('')\n","\n","\n","# Binary sentiment: rating â‰¥ 7 is positive (1), else negative (0)\n","df[\"label\"] = df[\"rating\"].apply(lambda x: 1 if x >= 7 else 0)\n","\n","# Take text and labels\n","texts = df[\"review\"].tolist()\n","labels = df[\"label\"].tolist()"],"metadata":{"id":"Wlua0k59QxgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertTokenizerFast\n","\n","tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n","\n","# Encode dataset\n","encodings = tokenizer(texts, truncation=True, padding=True, max_length=256)\n"],"metadata":{"id":"J6HxNWIdQ97R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","class DrugReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","# Train/test split\n","from sklearn.model_selection import train_test_split\n","train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, test_size=0.2)\n","\n","train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256)\n","test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=256)\n","\n","train_dataset = DrugReviewDataset(train_encodings, train_labels)\n","test_dataset = DrugReviewDataset(test_encodings, test_labels)\n"],"metadata":{"id":"cwnuY_OyRMyp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import f1_score\n","\n","model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=16,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    eval_strategy=\"epoch\",\n","    logging_dir='./logs',\n","    logging_steps=10\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    compute_metrics=lambda p: {\n","        \"accuracy\": (p.predictions.argmax(-1) == p.label_ids).mean(),\n","        \"f1\": f1_score(p.label_ids, p.predictions.argmax(-1))\n","    }\n",")\n","\n","# Train the model\n","trainer.train()"],"metadata":{"id":"0RqQXQwpRWtY","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"ok","timestamp":1752223594154,"user_tz":-330,"elapsed":245919,"user":{"displayName":"Aysha Hashif","userId":"03722952912424320427"}},"outputId":"9483037a-0bb4-4a20-976d-bd794b5f7205"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayshabeevi16\u001b[0m (\u001b[33mayshabeevi16-manappuram-insurance\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.0"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250711_084449-r39yhaqu</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/ayshabeevi16-manappuram-insurance/huggingface/runs/r39yhaqu' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/ayshabeevi16-manappuram-insurance/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/ayshabeevi16-manappuram-insurance/huggingface' target=\"_blank\">https://wandb.ai/ayshabeevi16-manappuram-insurance/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/ayshabeevi16-manappuram-insurance/huggingface/runs/r39yhaqu' target=\"_blank\">https://wandb.ai/ayshabeevi16-manappuram-insurance/huggingface/runs/r39yhaqu</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15/15 03:30, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.691466</td>\n","      <td>0.600000</td>\n","      <td>0.750000</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.687100</td>\n","      <td>0.662558</td>\n","      <td>0.700000</td>\n","      <td>0.823529</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.687100</td>\n","      <td>0.626546</td>\n","      <td>0.700000</td>\n","      <td>0.823529</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=15, training_loss=0.6737288157145183, metrics={'train_runtime': 232.4238, 'train_samples_per_second': 0.49, 'train_steps_per_second': 0.065, 'total_flos': 7550641723392.0, 'train_loss': 0.6737288157145183, 'epoch': 3.0})"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["model.save_pretrained(\"sentiment_model\")\n","tokenizer.save_pretrained(\"sentiment_model\")"],"metadata":{"id":"HqYMB9rJYa8P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1752223610674,"user_tz":-330,"elapsed":831,"user":{"displayName":"Aysha Hashif","userId":"03722952912424320427"}},"outputId":"2a0bda06-72cf-4ac8-ccb5-c84dffbc3de3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('sentiment_model/tokenizer_config.json',\n"," 'sentiment_model/special_tokens_map.json',\n"," 'sentiment_model/vocab.txt',\n"," 'sentiment_model/added_tokens.json',\n"," 'sentiment_model/tokenizer.json')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import streamlit as st\n","import torch\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n","import torch.nn.functional as F\n","\n","# Load model & tokenizer\n","model = DistilBertForSequenceClassification.from_pretrained(\"sentiment_model\")\n","tokenizer = DistilBertTokenizerFast.from_pretrained(\"sentiment_model\")\n","\n","st.title(\" Drug Review Sentiment Analyzer\")\n","\n","user_input = st.text_area(\"Enter a drug review:\")\n","\n","if st.button(\"Predict\"):\n","    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, padding=True)\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        probs = F.softmax(outputs.logits, dim=1)\n","        confidence = probs.max().item()\n","        label = torch.argmax(probs).item()\n","        sentiment = \"Positive\" if label == 1 else \"Negative\"\n","\n","    st.markdown(f\"### Sentiment: **{sentiment}**\")\n","    st.markdown(f\"Confidence: `{confidence:.2f}`\")\n"],"metadata":{"id":"Oz4aBRLnb0OC"},"execution_count":null,"outputs":[]}]}